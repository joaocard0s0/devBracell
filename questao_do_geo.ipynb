{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3574268",
   "metadata": {
    "id": "b3574268"
   },
   "source": [
    "## <font color=green> O objetivo do teste é aplicar operações em vetores e dados raster utilizando python, e elaboração de figuras.\n",
    "\n",
    "## <font color=green> Recomendamos a utilização de bibliotecas opensource como o geopandas, rasterio, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8479bb",
   "metadata": {},
   "source": [
    "## Considerações\n",
    "\n",
    "- Foi realizado funções para reaproveitamento de código;\n",
    "\n",
    "- Os resultados estarão em uma pasta de output;\n",
    "\n",
    "- É necessário fazer download dos arquivos contidos no drive e deixar dentro de \"Imagem/drive\", deixar o arquivo zipado, assim como veio do drive;\n",
    "\n",
    "- O teste 06 está serial, mas poderia tranquilamente ser usada em paralelo afim de otimização;\n",
    "\n",
    "- A biblioteca usada para manipulação de imagem georeferenciada foi a rasterio devido a facilidade de instalação, entretanto fica o\n",
    "                                                                atento que a biblioteca gdal é mais otimizada (gdal_calc, gdal_warp).\n",
    "\n",
    "- Devido ao tempo, não foi treinado um modelo para o desafio 09, apenas com indice vegetativo não é possível a indetificação das plantas com precisão;\n",
    "\n",
    "- Foi testado inúmeros indices (MPRI, VARI, EXG, GLI), e o que melhor se destacou foi o VARI;\n",
    "\n",
    "- A questão número 07 não consegui compreender pois na questão 3 não teve imagem e as estatísticas zonais para cada talhão (polygon_test.geojson) foi\n",
    "realizada na questão 05\n",
    "\n",
    "\n",
    "\n",
    "*\"Utilizando a classe agricultura identificada pelo mapbiomas (ano 2020), realize a intersecção nas áreas das fazendas e calcule as estatísticas zonais de média, mínima, máxima e desvio padrão de NDVI com a imagem fornecida na questão 3.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0338b4",
   "metadata": {},
   "source": [
    "## Recomendações:\n",
    "- python==3.10.8\n",
    "- geopandas==0.11\n",
    "- rasterio==1.3.9\n",
    "- shapely==1.8.0\n",
    "- numpy==1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e8af08",
   "metadata": {},
   "source": [
    "» Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321ee2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.validation import make_valid\n",
    "from rasterio.mask import mask\n",
    "from rasterstats import zonal_stats\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import zipfile\n",
    "import shapely\n",
    "import shutil\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5775a115",
   "metadata": {},
   "source": [
    "» Funcões para aproveitamento de código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a2f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_polygons()->gpd.GeoDataFrame:\n",
    "    name_file = \"polygons_test.GeoJSON\"\n",
    "    # Reading file polygons\n",
    "    gdf_polygons = gpd.read_file(os.path.join('GeoJson', name_file))\n",
    "\n",
    "    return gdf_polygons\n",
    "\n",
    "def read_uc()->gpd.GeoDataFrame:\n",
    "    name_file = \"layer_UCs.GeoJSON\"\n",
    "    # Reading file layer UC\n",
    "    gdf_uc = gpd.read_file(os.path.join('GeoJson', name_file))\n",
    "    # Fix any geometry invalid\n",
    "    gdf_uc.geometry = list(map(lambda x: make_valid(x), gdf_uc.geometry))\n",
    "    \n",
    "    return gdf_uc\n",
    "\n",
    "def explode_geometry(gdf:gpd.GeoDataFrame)->gpd.GeoDataFrame:\n",
    "    \"\"\"Explode geodataframe and reset index\n",
    "\n",
    "    Args:\n",
    "        gdf (gpd.GeoDataFrame): GeoDataFrame to explode\n",
    "\n",
    "    Returns:\n",
    "        gpd.GeoDataFrame: GeoDataFrame exploded\n",
    "    \"\"\"\n",
    "    gdf = gdf.reset_index(drop=True)\n",
    "    gdf = gdf.explode(ignore_index=True)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "def search_and_copy_files(main_folder_path, destination_folder_path, file_name_parts):\n",
    "    for root, dirs, files in os.walk(main_folder_path):\n",
    "        for file in files:\n",
    "            for file_name_part in file_name_parts:\n",
    "                if file_name_part in file and not \"MSK\" in file:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    shutil.copy(file_path, destination_folder_path)\n",
    "                    print(f'File {file} copied to {destination_folder_path}')\n",
    "\n",
    "def check_files():\n",
    "    \"\"\"You need to download the files and leave them in the drive folder with keys name\n",
    "    \"\"\"\n",
    "    base_path = os.path.join(\"Imagem\", \"drive\")\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "    links = {\"T22LHH_20211006T132239_4326\" :\"https://drive.google.com/file/d/1sV3TGy9OLnvhzAcZF5Qo3laSb2UXDJUN/view?usp=sharing\",\n",
    "            \"T22LHH_20211220T132234\" :\"https://drive.google.com/file/d/1vr_vnW-fZsoTyV5gkt7M7t73MlGzEcmC/view?usp=sharing\",\n",
    "            \"T22LHH_20220228T132236\" :\"https://drive.google.com/file/d/1y7ki4K21T2xUQx0d3JiKBTzOrZxFh8OG/view?usp=sharing\"}\n",
    "   \n",
    "    for folder , url in links.items():\n",
    "        output = os.path.join(f\"{os.path.join(base_path, folder)}\")\n",
    "        path_zip = f'{output}.zip'\n",
    "        # Dowload files\n",
    "        if not os.path.exists(path_zip):\n",
    "           print(f\"DO DOWLOAD {url}\")\n",
    "           print(f\"Insert zip into {base_path}\")\n",
    "           quit()\n",
    "        \n",
    "        # Extract zip file\n",
    "        if not os.path.isdir(output):\n",
    "            with zipfile.ZipFile(path_zip, 'r') as zip_ref:\n",
    "                zip_ref.extractall(output) \n",
    "\n",
    "                # Get band 04 and 08 from link\n",
    "                if folder == \"T22LHH_20211220T132234\" or folder == \"T22LHH_20220228T132236\":\n",
    "                    search_and_copy_files(output, output, [\"B04.jp2\",\"B08.jp2\"])\n",
    "\n",
    "\n",
    "def save_tif(output_path:str, image:np.array, out_meta:dict):\n",
    "    \"\"\"Save tif\n",
    "\n",
    "    Args:\n",
    "        output_path (str): path to save tif\n",
    "        image (np.array): array with image\n",
    "        out_meta (dict): meta from src.meta\n",
    "        type (rasterio.dtype, Optional): dtype to save file. Default float32\n",
    "    \"\"\"\n",
    "    bands = 1 if len(image.shape) < 3 else image.shape[0]\n",
    "    out_meta.update({\"count\": bands})\n",
    "    \n",
    "    if os.path.exists(output_path):return\n",
    "    with rasterio.open(output_path, \"w\", **out_meta) as dest:\n",
    "        if bands == 1 and len(image.shape) < 3:\n",
    "            dest.write(image, 1)\n",
    "        elif bands == 1 and len(image.shape) == 3:\n",
    "            dest.write(image[0,:,:], 1)\n",
    "        else:\n",
    "            dest.write(image)\n",
    "\n",
    "def calc_NDVI(array:np.array)->np.array:\n",
    "    \"\"\"Calc NDVI with array, \n",
    "       channel  | channel 0 = red    |  \n",
    "                | channel -1 = NIR |     \n",
    "               \n",
    "    Args:\n",
    "        array (np.array): array with R in first channel and NIR in last\n",
    "\n",
    "    Returns:\n",
    "        np.array: NDVI array\n",
    "    \"\"\"    \n",
    "    # Get red band\n",
    "    R = array[0, :, :].astype(rasterio.float32)\n",
    "    # Get NIR band\n",
    "    NIR = array[-1, :, :].astype(rasterio.float32)\n",
    "    \n",
    "    # Calc \n",
    "    num = (NIR - R)\n",
    "    den = (NIR + R)\n",
    "    # Division without 0\n",
    "    ndvi = np.where(den == 0, 0, num / den)\n",
    "\n",
    "    return ndvi\n",
    "\n",
    "def clip_image(path_output_clip:str, path_image:str, gdf_polygons:gpd.GeoDataFrame):\n",
    "    \"\"\"Clip image tif by field \n",
    "\n",
    "    Args:\n",
    "        path_output_clip (str): path to save file .tif\n",
    "        path_image (str): path origin tif\n",
    "        gdf_polygons (gpd.GeoDataFrame): field to clip\n",
    "    \"\"\"\n",
    "    # Clip image \n",
    "    with rasterio.open(path_image) as src:\n",
    "        crs_image = src.crs['init'].upper()\n",
    "        if gdf_polygons.crs != crs_image:\n",
    "            gdf_polygons = gdf_polygons.to_crs(crs_image)\n",
    "\n",
    "        out_image_field, out_transform_field = mask(src, gdf_polygons.geometry, crop=True)\n",
    "        \n",
    "        # Update meta\n",
    "        out_meta = src.profile.copy()\n",
    "        out_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"height\": out_image_field.shape[1],\n",
    "            \"width\": out_image_field.shape[2],\n",
    "            \"transform\": out_transform_field\n",
    "        })\n",
    "        # Save tif\n",
    "        save_tif(path_output_clip, out_image_field, out_meta)\n",
    "\n",
    "def read_tif(path:str)->tuple:\n",
    "    \"\"\"Read tif with rasterio\n",
    "\n",
    "    Args:\n",
    "        path (str): image path\n",
    "\n",
    "    Returns:\n",
    "        tuple: array and src\n",
    "    \"\"\"\n",
    "    with rasterio.open(path) as src:\n",
    "        array = src.read()\n",
    "\n",
    "        return array, src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1192a44",
   "metadata": {
    "id": "b1192a44"
   },
   "source": [
    "### Questão 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7258a4",
   "metadata": {
    "id": "6c7258a4"
   },
   "source": [
    "- Encontrar geometrias inválidas no arquivo polygons_test.GeoJSON. Propor um método de correção em python e aplicá-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d7b90b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 10 invalid geometry\n",
      "      ix                                           geometry\n",
      "0      0  MULTIPOLYGON (((-47.81127 -15.74775, -47.81123...\n",
      "1      1  POLYGON ((-47.81029 -15.52409, -47.80959 -15.5...\n",
      "2      2  POLYGON ((-47.51729 -15.67025, -47.51667 -15.6...\n",
      "3      3  POLYGON ((-47.65172 -15.68741, -47.65169 -15.6...\n",
      "4      4  POLYGON ((-47.78683 -15.81563, -47.77784 -15.8...\n",
      "..   ...                                                ...\n",
      "695  695  POLYGON ((-47.71776 -15.85125, -47.71519 -15.8...\n",
      "696  696  POLYGON ((-47.61052 -15.87739, -47.61019 -15.8...\n",
      "697  697  POLYGON ((-47.65166 -15.65142, -47.65163 -15.6...\n",
      "698  698  POLYGON ((-47.74000 -15.74298, -47.73973 -15.7...\n",
      "699  699  POLYGON ((-47.72839 -15.75270, -47.72813 -15.7...\n",
      "\n",
      "[700 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def test_01()->gpd.GeoDataFrame:\n",
    "    # Read polygons\n",
    "    gdf_polygons = read_polygons()\n",
    "    # Find invalid geometry\n",
    "    invalid_geometry = gdf_polygons[~gdf_polygons.geometry.is_valid]\n",
    "    # Count geometry invalid\n",
    "    print(f'Have {len(invalid_geometry)} invalid geometry')\n",
    "    # Fix geometry\n",
    "    gdf_polygons.geometry = list(map(lambda x: make_valid(x), gdf_polygons.geometry))\n",
    "\n",
    "    return gdf_polygons\n",
    "\n",
    "gdf = test_01()\n",
    "print(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950d1279",
   "metadata": {
    "id": "950d1279"
   },
   "source": [
    "### Questão 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401aeeef",
   "metadata": {
    "id": "401aeeef"
   },
   "source": [
    "- Calcular a área dos polígonos em hectares;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af616a6",
   "metadata": {
    "id": "8af616a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 10 invalid geometry\n",
      "Have 56698.82 hectares in layer_UCs\n",
      "      ix                                           geometry      area_ha\n",
      "0      0  MULTIPOLYGON (((-47.81127 -15.74775, -47.81123...  1902.251064\n",
      "1      1  POLYGON ((-47.81029 -15.52409, -47.80959 -15.5...  1373.060436\n",
      "2      2  POLYGON ((-47.51729 -15.67025, -47.51667 -15.6...  1263.517506\n",
      "3      3  POLYGON ((-47.65172 -15.68741, -47.65169 -15.6...  1180.850654\n",
      "4      4  POLYGON ((-47.78683 -15.81563, -47.77784 -15.8...  1100.682731\n",
      "..   ...                                                ...          ...\n",
      "695  695  POLYGON ((-47.71776 -15.85125, -47.71519 -15.8...     2.005135\n",
      "696  696  POLYGON ((-47.61052 -15.87739, -47.61019 -15.8...     2.004934\n",
      "697  697  POLYGON ((-47.65166 -15.65142, -47.65163 -15.6...     2.004931\n",
      "698  698  POLYGON ((-47.74000 -15.74298, -47.73973 -15.7...     2.004867\n",
      "699  699  POLYGON ((-47.72839 -15.75270, -47.72813 -15.7...     2.004745\n",
      "\n",
      "[700 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def test_02()->gpd.GeoDataFrame:\n",
    "    # Read polygons\n",
    "    gdf_polygons = test_01()\n",
    "    # Calc area in hectare\n",
    "    meters_per_hectare = 1e4\n",
    "    # Find utm crs\n",
    "    crs_utm =  gdf_polygons.estimate_utm_crs()\n",
    "    # Calc area by polygon\n",
    "    gdf_polygons['area_ha'] = gdf_polygons.to_crs(crs_utm).area/meters_per_hectare\n",
    "    # Show area\n",
    "    print(f'Have {round(gdf_polygons.area_ha.sum(), 2)} hectares in layer_UCs')\n",
    "\n",
    "    return gdf_polygons\n",
    "\n",
    "gdf = test_02()\n",
    "print(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b84c71",
   "metadata": {
    "id": "d3b84c71"
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7850e892",
   "metadata": {
    "id": "7850e892"
   },
   "source": [
    "### Questão 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e64bb49",
   "metadata": {
    "id": "4e64bb49"
   },
   "source": [
    "- Utilizando o layer_UCs.GeoJSON, obter para cada polígono se há intersect com alguma UC. Calcular a área de intersect e obter o nome da UC correspondente a cada polígono;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba78620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 10 invalid geometry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64689/342454538.py:32: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1903.76' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  gdf_polygons.at[i, 'intersect_area'] = round(area_ha, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ix                                           geometry  intersect_area  \\\n",
      "0      0  POLYGON ((-47.81127 -15.74775, -47.81123 -15.7...            0.00   \n",
      "1      0  POLYGON ((-47.81036 -15.71139, -47.81031 -15.7...         1903.76   \n",
      "2      1  POLYGON ((-47.81029 -15.52409, -47.80959 -15.5...         1373.06   \n",
      "3      2  POLYGON ((-47.51729 -15.67025, -47.51667 -15.6...         1265.25   \n",
      "4      3  POLYGON ((-47.65172 -15.68741, -47.65169 -15.6...         1180.85   \n",
      "..   ...                                                ...             ...   \n",
      "703  695  POLYGON ((-47.71776 -15.85125, -47.71519 -15.8...            2.01   \n",
      "704  696  POLYGON ((-47.61052 -15.87739, -47.61019 -15.8...            2.00   \n",
      "705  697  POLYGON ((-47.65166 -15.65142, -47.65163 -15.6...            2.00   \n",
      "706  698  POLYGON ((-47.74000 -15.74298, -47.73973 -15.7...            2.00   \n",
      "707  699  POLYGON ((-47.72839 -15.75270, -47.72813 -15.7...            2.00   \n",
      "\n",
      "                                        UC_intersected  \n",
      "0       ÁREA DE PROTEÇÃO AMBIENTAL DO PLANALTO CENTRAL  \n",
      "1    ÁREA DE PROTEÇÃO AMBIENTAL DA BACIA DO RIO SÃO...  \n",
      "2       ÁREA DE PROTEÇÃO AMBIENTAL DO PLANALTO CENTRAL  \n",
      "3    ÁREA DE PROTEÇÃO AMBIENTAL DA BACIA DO RIO SÃO...  \n",
      "4    ÁREA DE PROTEÇÃO AMBIENTAL DA BACIA DO RIO SÃO...  \n",
      "..                                                 ...  \n",
      "703  ÁREA DE PROTEÇÃO AMBIENTAL DA BACIA DO RIO SÃO...  \n",
      "704     ÁREA DE PROTEÇÃO AMBIENTAL DO PLANALTO CENTRAL  \n",
      "705  ÁREA DE PROTEÇÃO AMBIENTAL DA BACIA DO RIO SÃO...  \n",
      "706  ÁREA DE PROTEÇÃO AMBIENTAL DA BACIA DO RIO SÃO...  \n",
      "707  ÁREA DE PROTEÇÃO AMBIENTAL DA BACIA DO RIO SÃO...  \n",
      "\n",
      "[708 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def test_03()->gpd.GeoDataFrame:\n",
    "    # Reading geodataframe \n",
    "    gdf_polygons = test_01()\n",
    "    gdf_uc = read_uc()\n",
    "\n",
    "    #Multipart to single part\n",
    "    gdf_polygons = explode_geometry(gdf_polygons)\n",
    "    gdf_uc = explode_geometry(gdf_uc)\n",
    "\n",
    "    # Columns to get informations\n",
    "    gdf_polygons['intersect_area'] = 0.0\n",
    "    gdf_polygons['UC_intersected'] = None\n",
    "\n",
    "    # Informations\n",
    "    meters_per_hectare = 1e4\n",
    "    crs_utm = gdf_polygons.estimate_utm_crs()\n",
    "\n",
    "    # For each polygon find intersection area with UC\n",
    "    for i, polygon in gdf_polygons.iterrows():\n",
    "        # Get just intersection area\n",
    "        intersection = gdf_uc[gdf_uc.intersects(polygon.geometry)]\n",
    "        # Sum area in hectare\n",
    "        just_intersection = intersection.intersection(polygon.geometry)\n",
    "        if len(just_intersection) > 0:\n",
    "            area_ha = sum(just_intersection.to_crs(crs_utm).area/meters_per_hectare)\n",
    "        else:\n",
    "            area_ha = 0\n",
    "\n",
    "        # Names UC intersected concated with \",\"\n",
    "        name_uc_intesected = ', '.join(list(intersection.nome))\n",
    "        # Set informations in polygons\n",
    "        gdf_polygons.at[i, 'intersect_area'] = round(area_ha, 2)\n",
    "        gdf_polygons.at[i, 'UC_intersected'] = name_uc_intesected\n",
    "    \n",
    "    return gdf_polygons\n",
    "\n",
    "gdf = test_03()\n",
    "print(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d60d0",
   "metadata": {
    "id": "938d60d0"
   },
   "source": [
    "### Questão 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b24b194",
   "metadata": {
    "id": "8b24b194"
   },
   "source": [
    "- Utilizando a imagem de satelite abaixo, calcule o NDVI e recorte a imagem utilizando os polígonos obtidos no item anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbb664e",
   "metadata": {
    "id": "2dbb664e"
   },
   "source": [
    "- Imagem de satelite de 06/10/2021: https://drive.google.com/file/d/1sV3TGy9OLnvhzAcZF5Qo3laSb2UXDJUN/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5302598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_04(numpy_ndvi:bool=False):\n",
    "    \"\"\"Test 04\n",
    "\n",
    "    Args:\n",
    "        numpy_ndvi (bool, optional): Flag to get np.array, NDVI. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        str|(np.array, rasterio.src): path with NDVI or array and src\n",
    "    \"\"\"\n",
    "    # Check files\n",
    "    check_files()\n",
    "\n",
    "    # Get image path\n",
    "    path_base = os.path.join(\"Imagem\", \"output\")\n",
    "    os.makedirs(path_base, exist_ok=True)\n",
    "    path_image = os.path.join(\"Imagem\", \"drive\", \"T22LHH_20211006T132239_4326\", \"T22LHH_20211006T132239_4326.tif\")\n",
    "    # Path to output cliped image\n",
    "    path_output_clip = os.path.join(path_base, \"cliped_by_fied.tif\")\n",
    "    # Path to NDVI\n",
    "    path_output_NDVI = os.path.join(path_base, \"NDVI.tif\")\n",
    "\n",
    "    # Check if file exists\n",
    "    if os.path.exists(path_output_NDVI) and not numpy_ndvi:\n",
    "        return path_output_NDVI\n",
    "    \n",
    "    # Reading file\n",
    "    gdf_polygons = test_01()\n",
    "\n",
    "    # CLip image\n",
    "    clip_image(path_output_clip, path_image, gdf_polygons)\n",
    "\n",
    "    # NDVI equation (NIR (4) - red (1)) / (NIR (4) + red (1))\n",
    "    with rasterio.open(path_output_clip) as src:\n",
    "        # Get meta\n",
    "        meta = src.profile\n",
    "        # read array\n",
    "        shape = src.read()\n",
    "        # Calc ndvi\n",
    "        ndvi = calc_NDVI(shape)\n",
    "\n",
    "        if numpy_ndvi:\n",
    "            return ndvi, src\n",
    "        \n",
    "        # Update meta\n",
    "        ndvi_meta = meta.copy()\n",
    "        ndvi_meta.update(dtype=rasterio.float32)\n",
    "        # Save image .tif\n",
    "        save_tif(path_output_NDVI, ndvi, ndvi_meta)\n",
    "    \n",
    "    return path_output_NDVI\n",
    "\n",
    "test_04()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155e44eb",
   "metadata": {
    "id": "155e44eb"
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7086d4ea",
   "metadata": {
    "id": "7086d4ea"
   },
   "source": [
    "### Questão 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad50c2f",
   "metadata": {
    "id": "3ad50c2f"
   },
   "source": [
    "- Calcular nas áreas das fazendas estatísticas zonais de média, mínimo, máximo e desvio padrão de NDVI referente a cada imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c964e6a",
   "metadata": {
    "id": "6c964e6a"
   },
   "outputs": [],
   "source": [
    "def test_05()->gpd.GeoDataFrame:\n",
    "    # Reading file\n",
    "    gdf_polygons = test_01()\n",
    "    # Array NDVI\n",
    "    ndvi, src = test_04(numpy_ndvi=True)\n",
    "\n",
    "    # Calc stats NDVI (MIN, MAX, MEAN, STD) to each field\n",
    "    stats = zonal_stats(gdf_polygons, ndvi, affine=src.transform, stats=['mean', 'min', 'max', 'std'])\n",
    "\n",
    "    # Add values by field\n",
    "    gdf_polygons['mean'] = [stat['mean'] for stat in stats]\n",
    "    gdf_polygons['min'] = [stat['min'] for stat in stats]\n",
    "    gdf_polygons['max'] = [stat['max'] for stat in stats]\n",
    "    gdf_polygons['std'] = [stat['std'] for stat in stats]\n",
    "\n",
    "    return gdf_polygons\n",
    "\n",
    "test_05()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79239e46",
   "metadata": {
    "id": "79239e46"
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3a4958",
   "metadata": {
    "id": "ff3a4958"
   },
   "source": [
    "### Questão 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65321f37",
   "metadata": {
    "id": "65321f37"
   },
   "source": [
    "- Gerar um mapa de NDVI recortado para cada polígono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7989ce18",
   "metadata": {
    "id": "7989ce18"
   },
   "outputs": [],
   "source": [
    "def test_06():\n",
    "    # Reading file\n",
    "    gdf_polygons = test_01()\n",
    "    # Path ndvi\n",
    "    path_output_NDVI = test_04()\n",
    "    # Path to save maps\n",
    "    path_base_save = os.path.join(\"Imagem\", \"output\", \"Mapas\")\n",
    "    os.makedirs(path_base_save, exist_ok=True)\n",
    "\n",
    "    # Map NDVI to each polygon\n",
    "    with rasterio.open(path_output_NDVI) as src:\n",
    "\n",
    "        for i, polygon in gdf_polygons.iterrows():\n",
    "            image, transform = mask(src, [shapely.geometry.mapping(polygon.geometry)], crop=True)\n",
    "\n",
    "            ndvi = image[0]\n",
    "            cmap = plt.cm.Spectral\n",
    "            norm = plt.Normalize(vmin=-1, vmax=1)  \n",
    "            ndvi_colored = cmap(norm(ndvi))\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(10, 10))\n",
    "            ax.imshow(ndvi_colored, extent=(transform[2], transform[2] + transform[0] * image.shape[2],\n",
    "                                            transform[5] + transform[4] * image.shape[1], transform[5]))\n",
    "            \n",
    "            ax.set_title(f'NDVI - Talhão {i}')\n",
    "            ax.axis('off')\n",
    "\n",
    "            # Add geometry field\n",
    "            gdf_polygons.loc[[i]].boundary.plot(ax=ax, edgecolor='black')\n",
    "\n",
    "            # save map PDF\n",
    "            out_pdf_path = os.path.join(path_base_save, f'talhao_{i}_ndvi.pdf')\n",
    "            plt.savefig(out_pdf_path, bbox_inches='tight', dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "test_06()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefbacdc",
   "metadata": {
    "id": "cefbacdc"
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6985e87d",
   "metadata": {
    "id": "6985e87d"
   },
   "source": [
    "### Questão 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0105c0a",
   "metadata": {
    "id": "f0105c0a"
   },
   "source": [
    "- Utilizando a classe agricultura identificada pelo mapbiomas (ano 2020), realize a intersecção nas áreas das fazendas e calcule as estatísticas zonais de média, mínima, máxima e desvio padrão de NDVI com a imagem fornecida na questão 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c5d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_07():\n",
    "    return test_05()\n",
    "\n",
    "\n",
    "gdf = test_07()\n",
    "print(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c2e3a",
   "metadata": {
    "id": "eb4c2e3a"
   },
   "source": [
    "### Questão 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b6e3e7",
   "metadata": {
    "id": "87b6e3e7"
   },
   "source": [
    "- Utilizando a imagem de satelite abaixo, gerar plot de uma serie temporal (inicio, meio e fim da safra) utilizando o NDVI em dois talhoes a sua escolha."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc81045",
   "metadata": {
    "id": "3bc81045"
   },
   "source": [
    "- Imagem de satelite de 06/10/2021: https://drive.google.com/file/d/1sV3TGy9OLnvhzAcZF5Qo3laSb2UXDJUN/view?usp=sharing\n",
    "- Imagem de satelite de 20/12/2021: https://drive.google.com/file/d/1vr_vnW-fZsoTyV5gkt7M7t73MlGzEcmC/view?usp=sharing\n",
    "- Imagem de satelite de 28/02/2022: https://drive.google.com/file/d/1y7ki4K21T2xUQx0d3JiKBTzOrZxFh8OG/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce778da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_08():\n",
    "    # Sentinel-2\n",
    "    # band 4 ==  RED\n",
    "    # band 8 ==  NIR\n",
    "    band_red = \"B04\"\n",
    "    band_nir = \"B08\"\n",
    "\n",
    "    # Reading file\n",
    "    gdf_polygons = test_01()\n",
    "    gdf_polygons = gdf_polygons.iloc[[1, 3]]\n",
    "\n",
    "    # Check files\n",
    "    check_files()\n",
    "\n",
    "    # Need clip all images by field\n",
    "    base_path_serie = os.path.join(\"Imagem\", \"drive\")\n",
    "    # Folder to clip images\n",
    "    folders = [\"T22LHH_20211220T132234\", \"T22LHH_20220228T132236\", \"T22LHH_20211006T132239_4326\"]\n",
    "    ext_image = (\".jp2\", \".tif\")\n",
    "\n",
    "    # Join band red and NIR\n",
    "    # CLip all images\n",
    "    paths_images_cliped = {}\n",
    "    for folder in folders:\n",
    "        paths = []\n",
    "        for file in os.scandir(os.path.join(base_path_serie,folder)):\n",
    "            # Check if is a image\n",
    "            if file.name.endswith(ext_image) and not \"xml\" in file.name and not \"_cliped\" in file.name:\n",
    "                # Clip image\n",
    "                ext = file.name.split('.')[-1]\n",
    "                path_image = file.path.replace(f'.{ext}', f\"_cliped.{ext}\")\n",
    "                 # Add path to list \n",
    "                paths.append(path_image)\n",
    "                if os.path.isfile(path_image):continue \n",
    "                clip_image(path_image, file.path, gdf_polygons)\n",
    "               \n",
    "        \n",
    "        # Get all paths with cliped image\n",
    "        paths_images_cliped[folder] = paths\n",
    "    \n",
    "    # Create var to array\n",
    "    ndvi_06_10_21 = (None, \"T22LHH_20211006T132239_4326\")\n",
    "    ndvi_20_12_21 = (None, \"T22LHH_20211220T132234\")\n",
    "    ndvi_28_02_22 = (None, \"T22LHH_20220228T132236\")\n",
    "\n",
    "    # Read array and calc NDVI\n",
    "    for folder, path_file in paths_images_cliped.items():\n",
    "        for file in path_file:\n",
    "            if band_red in file:\n",
    "                red, _ = read_tif(file)\n",
    "\n",
    "            elif band_nir in file:\n",
    "                nir, _ = read_tif(file)\n",
    "            \n",
    "            else:\n",
    "                ndvi_06_10 = read_tif(file)[0]\n",
    "\n",
    "        if folder == ndvi_06_10_21[1]:\n",
    "            ndvi_06_10_21 = (calc_NDVI(ndvi_06_10), \"T22LHH_20211006T132239_4326\")\n",
    "            continue\n",
    "\n",
    "        # Concatenate values\n",
    "        join_band = np.concatenate((red, nir))\n",
    "        # Calc NDVI \n",
    "        ndvi = calc_NDVI(join_band)\n",
    "        # assign to var\n",
    "        if folder == ndvi_20_12_21[1]:\n",
    "            ndvi_20_12_21 = (ndvi, folder)\n",
    "        elif folder == ndvi_28_02_22[1]:\n",
    "            ndvi_28_02_22 = (ndvi, folder)\n",
    "    \n",
    "    ndvi_images = [ (ndvi_06_10_21[0], \"06/10/2021\"),\n",
    "                    (ndvi_20_12_21[0], \"20/12/2021\"),\n",
    "                    (ndvi_28_02_22[0], \"28/02/2022\")\n",
    "                    ]\n",
    "    \n",
    "    # Create pdf\n",
    "    plt.figure(figsize=(12, 14)) \n",
    "    for i, (ndvi_array, date) in enumerate(ndvi_images):\n",
    "        ax = plt.subplot(3, 1, i + 1)\n",
    "        img = plt.imshow(ndvi_array, cmap='RdYlGn')\n",
    "        plt.title(f\"NDVI {date}\", fontsize=16)\n",
    "        plt.axis('off')\n",
    "\n",
    "        cbar = plt.colorbar(img, orientation='horizontal', fraction=0.046, pad=0.1, ax=ax)\n",
    "        cbar.set_label('NDVI Value', fontsize=12)\n",
    "        cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "    # Salva o PDF\n",
    "    plt.tight_layout()\n",
    "    base_path = os.path.join(\"Imagem\", \"output\")\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    plt.savefig(os.path.join(base_path, 'Serie_temporal_teste 08.pdf'))\n",
    "\n",
    "test_08()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cad059",
   "metadata": {
    "id": "83cad059"
   },
   "source": [
    "### Questão 9\n",
    "\n",
    "- Utilizando o Teste.jpg, obtenha uma classificação dos objetos na imagem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8626923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_09():\n",
    "    # Path image\n",
    "    file_path = os.path.join(\"Imagem\",\"Teste.jpg\")\n",
    "    # Path mask\n",
    "    base_path = os.path.join(\"Imagem\", \"output\")\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    mask_path = os.path.join(base_path, \"mask_test_09.jpg\")\n",
    "    # Reading file\n",
    "    with rasterio.open(file_path) as src:\n",
    "        array = src.read()\n",
    "        # Get bands\n",
    "        red = array[0,:,:].astype(rasterio.uint8)\n",
    "        green = array[1,:,:].astype(rasterio.uint8)\n",
    "        blue = array[2,:,:].astype(rasterio.uint8)\n",
    "         \n",
    "        #Calc VARI\n",
    "        den = green - red\n",
    "        num = green + red - blue\n",
    "        vari = np.where(den == 0, 0, num / den)\n",
    "\n",
    "        # Limiar \n",
    "        min_th = 2\n",
    "        max_th = 8\n",
    "        vari = np.where((vari >= min_th) & (vari <= max_th), vari, 0)\n",
    "\n",
    "        # Remove noise\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        vari = cv2.dilate(vari, kernel, iterations=1)\n",
    "        vari = cv2.erode(vari, kernel, iterations=1)\n",
    "        \n",
    "        meta = src.profile.copy()\n",
    "        meta.update(dtype=rasterio.uint8)\n",
    "\n",
    "        save_tif(mask_path, vari, meta)\n",
    "\n",
    "test_09()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
